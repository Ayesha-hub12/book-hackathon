"use strict";(globalThis.webpackChunkros2_textbook=globalThis.webpackChunkros2_textbook||[]).push([[764],{8453(e,n,t){t.d(n,{R:()=>o,x:()=>a});var i=t(6540);const s={},r=i.createContext(s);function o(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(r.Provider,{value:n},e.children)}},9821(e,n,t){t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>l});var i=t(4848),s=t(8453);const r={sidebar_position:3},o="Bridging AI Agents to ROS 2 Control",a={id:"python-agents/ai-integration",title:"Bridging AI Agents to ROS 2 Control",description:"Integrating AI with ROS 2 Systems",source:"@site/docs/python-agents/ai-integration.md",sourceDirName:"python-agents",slug:"/python-agents/ai-integration",permalink:"/book-hackathon/docs/python-agents/ai-integration",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/python-agents/ai-integration.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"rclpy Basics: Creating Nodes, Publishers, and Subscribers",permalink:"/book-hackathon/docs/python-agents/rclpy-basics"},next:{title:"Robot Structure with URDF",permalink:"/book-hackathon/docs/urdf-structure/"}},c={},l=[{value:"Integrating AI with ROS 2 Systems",id:"integrating-ai-with-ros-2-systems",level:2},{value:"AI Agent Architecture",id:"ai-agent-architecture",level:3},{value:"Simple AI Agent Pattern",id:"simple-ai-agent-pattern",level:3},{value:"Advanced Integration Patterns",id:"advanced-integration-patterns",level:3},{value:"1. Behavior Trees",id:"1-behavior-trees",level:4},{value:"2. Reinforcement Learning Integration",id:"2-reinforcement-learning-integration",level:4},{value:"Communication Patterns",id:"communication-patterns",level:3},{value:"Performance Considerations",id:"performance-considerations",level:3},{value:"Learning Objectives",id:"learning-objectives",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"bridging-ai-agents-to-ros-2-control",children:"Bridging AI Agents to ROS 2 Control"}),"\n",(0,i.jsx)(n.h2,{id:"integrating-ai-with-ros-2-systems",children:"Integrating AI with ROS 2 Systems"}),"\n",(0,i.jsx)(n.p,{children:"This section explores how to connect AI agents with ROS 2 control systems. We'll look at patterns for integrating decision-making algorithms with robotic control frameworks."}),"\n",(0,i.jsx)(n.h3,{id:"ai-agent-architecture",children:"AI Agent Architecture"}),"\n",(0,i.jsx)(n.p,{children:"An AI agent typically follows the PEAS (Percepts, Environment, Actuators, Sensors) model. In a ROS 2 context, this translates to:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Percepts"}),": Data received from ROS 2 topics (sensor data, camera feeds, etc.)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Environment"}),": The physical or simulated world the robot operates in"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Actuators"}),": Commands sent via ROS 2 topics/services (motor controls, grippers, etc.)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sensors"}),": Data publishers from hardware or simulation"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"simple-ai-agent-pattern",children:"Simple AI Agent Pattern"}),"\n",(0,i.jsx)(n.p,{children:"Here's a basic pattern for connecting an AI agent to ROS 2:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String, Float64\nfrom sensor_msgs.msg import LaserScan\nimport numpy as np\n\nclass AIAgentNode(Node):\n\n    def __init__(self):\n        super().__init__(\'ai_agent_node\')\n\n        # Subscribe to sensor data\n        self.subscription = self.create_subscription(\n            LaserScan,\n            \'laser_scan\',\n            self.sensor_callback,\n            10)\n\n        # Publish commands to robot\n        self.publisher = self.create_publisher(\n            Float64,\n            \'robot_command\',\n            10)\n\n        # Internal state for the AI agent\n        self.sensor_data = None\n        self.command_timer = self.create_timer(0.1, self.ai_decision_loop)\n\n    def sensor_callback(self, msg):\n        """Process incoming sensor data"""\n        self.sensor_data = msg.ranges  # Store laser scan data\n\n    def ai_decision_loop(self):\n        """Main AI decision-making loop"""\n        if self.sensor_data is not None:\n            # Simple obstacle avoidance AI\n            command = self.simple_navigation_ai(self.sensor_data)\n\n            # Publish command\n            cmd_msg = Float64()\n            cmd_msg.data = command\n            self.publisher.publish(cmd_msg)\n\n    def simple_navigation_ai(self, sensor_data):\n        """Simple navigation AI - avoid obstacles"""\n        # Find the direction with the most clearance\n        front_clearance = min(sensor_data[300:340])  # Front right\n        front_center = min(sensor_data[340:380])     # Front center\n        front_left = min(sensor_data[380:420])       # Front left\n\n        if front_center > 1.0:  # Clear path ahead\n            return 0.5  # Move forward\n        elif front_left > front_right:\n            return -0.3  # Turn left\n        else:\n            return 0.3  # Turn right\n\ndef main(args=None):\n    rclpy.init(args=args)\n    ai_agent = AIAgentNode()\n    rclpy.spin(ai_agent)\n    ai_agent.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,i.jsx)(n.h3,{id:"advanced-integration-patterns",children:"Advanced Integration Patterns"}),"\n",(0,i.jsx)(n.h4,{id:"1-behavior-trees",children:"1. Behavior Trees"}),"\n",(0,i.jsx)(n.p,{children:"Behavior trees are commonly used in robotics for complex decision making:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Example of how to structure a behavior tree node\nclass BehaviorTreeNode(Node):\n    def __init__(self):\n        super().__init__('behavior_tree_node')\n        # Implementation would include state management\n        # for complex AI decision trees\n"})}),"\n",(0,i.jsx)(n.h4,{id:"2-reinforcement-learning-integration",children:"2. Reinforcement Learning Integration"}),"\n",(0,i.jsx)(n.p,{children:"RL agents can be integrated with ROS 2 for learning-based control:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Simplified example of RL integration\nclass RLAgentNode(Node):\n    def __init__(self):\n        super().__init__('rl_agent_node')\n        # Initialize RL model\n        # Connect to ROS 2 topics for state and action\n"})}),"\n",(0,i.jsx)(n.h3,{id:"communication-patterns",children:"Communication Patterns"}),"\n",(0,i.jsx)(n.p,{children:"When integrating AI with ROS 2, consider these communication patterns:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"State-Action Loop"}),": AI agent receives state, processes, returns action"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Event-Driven"}),": AI agent responds to specific events or triggers"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Periodic Updates"}),": AI agent updates at regular intervals"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Hybrid Approach"}),": Combination of the above based on task requirements"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,i.jsx)(n.p,{children:"When integrating AI with ROS 2:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Latency"}),": AI processing should not introduce excessive delays"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Frequency"}),": Match AI decision frequency to control system requirements"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Resource usage"}),": Monitor CPU and memory usage of AI components"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Real-time constraints"}),": Consider if hard real-time requirements exist"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(n.p,{children:"After completing this section, you should be able to:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Design basic AI agents that interface with ROS 2 systems"}),"\n",(0,i.jsx)(n.li,{children:"Implement sensor processing and command generation patterns"}),"\n",(0,i.jsx)(n.li,{children:"Understand different integration architectures for AI-ROS systems"}),"\n",(0,i.jsx)(n.li,{children:"Consider performance implications of AI integration"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);